# -*- coding: utf-8 -*-
"""hw3_p2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17tlrYkJGu9hVc02FBK7m8m8OltIjx61p
"""

# Commented out IPython magic to ensure Python compatibility.
# mount drive, install kaggle, download the data, and unzip
from google.colab import drive
drive.mount('/content/gdrive')
# %cd /content/
!pip install -q kaggle
!pip install  --upgrade kaggle
!pip install -q python-levenshtein
# %rm -rf /root/.kaggle/
# %mkdir /root/.kaggle
# %cp /content/gdrive/My\ Drive/CMU11785-HW3/kaggle.json  /root/.kaggle/
# %cd /content/ 
!kaggle competitions download -q -c 11-785-fall-20-homework-3  && unzip -q \*.zip
!git clone --recursive https://github.com/parlance/ctcdecode.git
!pip install wget
# %cd ctcdecode
!pip install .
# %cd ..
!pip install python-Levenshtein
import Levenshtein

# Commented out IPython magic to ensure Python compatibility.
# Import packages
# %cd /content
import numpy as np
import torch
import sys
import torch.nn as nn
import torch.optim as optim
import os
import pandas as pd
import time
from torch.utils.data import DataLoader, Dataset
import Levenshtein as lev
import torch.nn.functional as F

from phoneme_list import N_PHONEMES, PHONEME_LIST, PHONEME_MAP
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence
from ctcdecode import CTCBeamDecoder

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

class myDataset(torch.utils.data.Dataset):
  # feature data : (Utterances, time step, 13)
  # labels       : (Utterances, frequencies), variable frequencies | order-aligned
  def __init__(self,Utterances,labels):
    self.Utterances = [self.normalize(u) for u in Utterances]
    self.labels     = labels 

  def __len__(self):
    return len(self.Utterances)


  def normalize(self,item):
    mu =  np.mean(item,axis=0)
    std = np.std(item,axis=0)
    item = (item-mu)/std
    return item


  def __getitem__(self,index):
    item  = self.Utterances[index]
    label = self.labels[index] + 1
    return torch.FloatTensor(item),torch.LongTensor(label) 


def collate(batch):
  
  Utterances        = [element[0] for element in batch]
  frames_len        = torch.LongTensor([len(frame)  for frame in Utterances])
  Utterances_padded = pad_sequence(Utterances,batch_first=True)


  labels            = [element[1] for element in batch]
  labels_padded     = pad_sequence(labels,batch_first=True)
  labels_len        = torch.LongTensor([len(t) for t in labels])

  return Utterances_padded, frames_len , labels_padded, labels_len

class testDataset(torch.utils.data.Dataset):
  # feature data : (Utterances, time step, 13)
  # labels       : (Utterances, frequencies), variable frequencies 
  def __init__(self,Utterances):
    self.Utterances = [self.normalize(u) for u in Utterances]
  

  def __len__(self):
    return len(self.Utterances)


  def normalize(self,item):
    mu =  np.mean(item,axis=0)
    std = np.std(item,axis=0)
    item = (item-mu)/std
    return item


  def __getitem__(self,index):
    item  = self.Utterances[index]
    return torch.FloatTensor(item),None


def testcollate(batch):
  
  Utterances        = [element[0] for element in batch]
  frames_len        = torch.LongTensor([len(frame)  for frame in Utterances])
  Utterances_padded = pad_sequence(Utterances,batch_first=True)

  return Utterances_padded, frames_len

train        = np.load('train.npy',allow_pickle=True,encoding='latin1')
train_labels = np.load('train_labels.npy',allow_pickle=True,encoding='latin1')
dev          = np.load('dev.npy',allow_pickle=True,encoding="latin1")
dev_labels   = np.load('dev_labels.npy',allow_pickle=True,encoding="latin1")
test        = np.load('test.npy',allow_pickle=True,encoding='latin1')

train_loader_args = dict(shuffle =True,batch_size=64,num_workers=4,collate_fn = collate, pin_memory=True)
dev_loader_args   = dict(shuffle=False,batch_size=32,num_workers=4,collate_fn = collate, pin_memory=True)
train_loader      = DataLoader(myDataset(train,train_labels),**train_loader_args)
dev_loader        = DataLoader(myDataset(dev,dev_labels),**dev_loader_args)
test_loader_args   = dict(shuffle=False,batch_size=32,num_workers=4,collate_fn = testcollate, pin_memory=True)
test_loader        = DataLoader(testDataset(test),**test_loader_args)

# Commented out IPython magic to ensure Python compatibility.
# change directory to hw3
# %cd /content/gdrive/My Drive/CMU11785-HW3/

class SpeechToPhoneme(nn.Module):
  def __init__(self):
    super(SpeechToPhoneme,self).__init__()
    self.conv1       = nn.Conv1d(13,128,kernel_size=1,bias=False) 
    self.bn1         = nn.BatchNorm1d(128)
    self.conv2       = nn.Conv1d(128,256,3,1,padding=1,bias=False)
    self.bn2         = nn.BatchNorm1d(256)
    self.conv3       = nn.Conv1d(256,256,3,1,padding=1,bias=False)
    self.bn3         = nn.BatchNorm1d(256)
    self.shortcut    = nn.Sequential(nn.Conv1d(13,256,3,1,1),nn.BatchNorm1d(256))
    self.rnn         = torch.nn.LSTM(256,512,bidirectional=True,num_layers=4,batch_first=True,dropout = 0.2)
    self.linear      = nn.Linear(512*2,512)
    self.dropout     = nn.Dropout(0.2)
    self.output      = nn.Linear(512,42)


  def forward(self,x,lengths): 
  #def forward(self, x):
    #print("x shape : {}".format(x.shape))
    out                = x.permute(0,2,1)  
    out                = F.relu(self.bn1(self.conv1(out)))
    out                = F.relu(self.bn2(self.conv2(out)))
    out                = F.relu(self.bn3(self.conv3(out)))
    #print("shape x : {}".format(out.shape))
    out               += self.shortcut(x.permute(0,2,1))
    # ResNET block for feature extraction 
    out                = out.permute(2,0,1)
    xpacked            = pack_padded_sequence(out,lengths,enforce_sorted=False)
    outpacked,hidden   = self.rnn(xpacked)
    out, outlengths    = pad_packed_sequence(outpacked,batch_first=True)
    out                = self.linear(out)
    out                = self.dropout(out)
    out_prob           = self.output(out).log_softmax(2)
    out_prob           = out_prob.permute(1,0,2)  
    return out_prob, lengths
    #return x

def init_weights(m):
  if type(m) == nn.Conv2d:    
    nn.init.kaiming_normal_(m.weight)
    if m.bias is not None:
      nn.init.zeros_(m.bias)     
  if type(m) == nn.Linear:
    nn.init.xavier_normal_(m.weight)

def save_model(net,epoch):
  # Specify a path
  newDir("saved_models2")
  PATH = f"/content/gdrive/My Drive/CMU11785-HW3/saved_models2/model_{epoch}.pt"
  print("----------- saving the model ....\n") 
  torch.save(net.state_dict(), PATH)

class newDir:
  def __init__(self,name):
    self.name = name
    if not os.path.exists(name):
        os.mkdir(name)
        print(f"{self.name} directory created! ")
    else :
        print(f"{self.name} directory exists! ")

class rmDir:
  def __init__(self,name):
    self.name = name
    if os.path.exists(name):
      os.rmdir(name)
      print(f"{self.name} directory is removed! ")
    else :
      print(f"{self.name} directory does not exist! ")

model = SpeechToPhoneme()
criterion = nn.CTCLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=5e-4,weight_decay=5e-5)
scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.85,
                                           patience=0, threshold=0.5)

# due to cuda memory error, I trained it for 10 epochs and then restarted training from there again 
model.load_state_dict(torch.load("/content/gdrive/My Drive/CMU11785-HW3/saved_models/model_10.pt"))

#model.apply(init_weights)
model = model.to(device)
print(model)
decoder = CTCBeamDecoder(labels=PHONEME_MAP, beam_width = 10,log_probs_input=True)

# majority of the following code is extension of the Recitation 7
for epoch in range(10):
  avgloss = 0 
  total = 0
  model.train()
  print("--"*20)
  print('Epoch : {:2d}, Learning rate : {:.2e} ' .format(epoch+1,optimizer.param_groups[0]['lr']))
  for batch_idx, (inputs,Input_lengths,targets,Target_lengths) in enumerate(train_loader):
      optimizer.zero_grad()

      inputs           = inputs.cuda()
      targets          = targets.cuda()
      Target_lengths   = Target_lengths.cuda()
      Input_lengths    = Input_lengths.cuda()
      log_probs, out_lens = model(inputs, Input_lengths.cpu())
    
      loss = criterion(log_probs,          # (T, N, C )
                       targets,            # (N, S)  
                       out_lens,           # (N,)
                       Target_lengths)     # (N,)
      avgloss = avgloss + loss.item()
      loss.backward()
      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) 
      optimizer.step()

      torch.cuda.empty_cache()
      del inputs
      del targets
      del Input_lengths
      del Target_lengths
      del log_probs
      del out_lens 

      if (batch_idx+1) % 100 == 0:
        print('Batch_index : {:5d}, Average training Loss/Batch: {:4.4f}'.format(batch_idx+1, avgloss/100.0))
        avgloss = 0.0

  with torch.no_grad():
    model.eval()
    dis = 0
    dev_count = 0 
    avg_dev_loss = 0
    for batch_idx, (inputs,xlens,targets,ylens) in enumerate(dev_loader):
      inputs = inputs.cuda()
      xlens = xlens.cuda()
      targets = targets.cuda()
      ylens =  ylens.cuda() 

      out, out_lens = model(inputs, xlens.cpu())
    
      loss = criterion(out, targets, out_lens, ylens)
      avg_dev_loss = avg_dev_loss + loss.item()
      out = torch.transpose(out,0,1)
      out_lens = out_lens.cpu()


      # copied from Recitation 7. didn't bother changing it. \cite {recitation 7}
      test_Y, _, _, test_Y_lens = decoder.decode(out, out_lens)
      
      for i in range(out.size()[0]):
          best_seq = test_Y[i, 0, :test_Y_lens[i, 0]]
          best_pron = ''.join(PHONEME_MAP[j] for j in best_seq)
          best_tar = ''.join(PHONEME_MAP[k] for k in targets[i] if k!=0) # cz it is padded with zeros
          dis = dis +  lev.distance(best_pron, best_tar)
          dev_count = dev_count + 1
      torch.cuda.empty_cache()
      del inputs
      del targets
      del ylens
      del xlens
    
    print('dev distance: ',dis/dev_count)
    print(' validation loss : ',avg_dev_loss/len(dev_loader))
  scheduler.step(avg_dev_loss/len(dev_loader))
  save_model(model,epoch+1) # save the model in case colab messes things up

# recitation 7 : just made some modification 
output = []
with torch.no_grad():
      model.eval()
      for batch_idx, (test_X,test_x_lens) in enumerate(test_loader):
        test_X = test_X.float().to(device)
        
        test_x_lens = test_x_lens.to(device)
        out, out_lens = model(test_X, test_x_lens.cpu())

        out = out.cpu()
        out_lens = out_lens.cpu()

        out = torch.transpose(out,0,1)
        test_Y, _, _, test_Y_lens = decoder.decode(out, out_lens)
        
        for i in range(out.size()[0]):
            best_seq = test_Y[i, 0, :test_Y_lens[i, 0]]
            best_pron = ''.join(PHONEME_MAP[j] for j in best_seq)
            output.append(best_pron)
        
        torch.cuda.empty_cache()    
        del test_X
        del test_x_lens
        del out
        del out_lens
        del test_Y
        del test_Y_lens

output = np.array(output)
np.save('output_test.npy',output)
index =np.arange(len(output))

import pandas as pd
df = pd.DataFrame({"id":index,"label":output})
df.to_csv('submission.csv',index=False)

!kaggle competitions submit -c 11-785-fall-20-homework-3-slack -f submission.csv -m "Message"